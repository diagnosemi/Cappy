{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2906d21-ee68-4a7c-ada3-04e323b205b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loading data\n",
    "import os\n",
    "os.environ[\"PTB_FOLDER_PATH\"] = \"/home/jupyter/data/files/ptbdb/1.0.0/\"\n",
    "import sys\n",
    "sys.path.insert(0,\"/home/jupyter/Cappy/ptd_data_handler\")\n",
    "sys.path.insert(0,\"/home/jupyter/Cappy/signal_processing\")\n",
    "from ptb_data_formatter import *\n",
    "from feature_extraction import *\n",
    "from custom_processing import *\n",
    "#all_patient_data = get_formatted_ptb_data()\n",
    "from ptb_xl_data_formatter import *\n",
    "os.environ[\"PTB_XL_FOLDER_PATH\"] = \"/home/jupyter/data/physionet.org/files/ptb-xl/1.0.1\"\n",
    "all_patient_data = get_formatted_ptb_xl_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c6250d-ba38-4d15-9ed3-767b1d6bbce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b223233-9187-45c8-9eba-380a2af6448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae82c67-5781-4bca-940d-3e70b636b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90043475-653d-4b3c-abdf-cbbfb98b8711",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  app.launch_new_instance()\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Create individual df for each class\n",
    "mi_df = pd.DataFrame()\n",
    "norm_df = pd.DataFrame()\n",
    "non_mi_df = pd.DataFrame()\n",
    "\n",
    "for recording in all_patient_data.keys():\n",
    "    label = all_patient_data[recording][\"diagnostic_class\"][0]\n",
    "    signal = all_patient_data[recording][\"I\"]\n",
    "    \n",
    "    # Clean Signal\n",
    "    signal = clean_ecg_signal(signal, old_fs=1000)\n",
    "    signal = pd.DataFrame(signal)\n",
    "    if label == \"mi\":\n",
    "        mi_df[recording] = signal\n",
    "    elif label == \"norm\":\n",
    "        norm_df[recording] = signal\n",
    "    elif label == \"non_mi\":\n",
    "        non_mi_df[recording] = signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c44118d-d371-4fd8-8530-db70995e34ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg_id_1</th>\n",
       "      <th>ecg_id_2</th>\n",
       "      <th>ecg_id_3</th>\n",
       "      <th>ecg_id_4</th>\n",
       "      <th>ecg_id_5</th>\n",
       "      <th>ecg_id_6</th>\n",
       "      <th>ecg_id_7</th>\n",
       "      <th>ecg_id_9</th>\n",
       "      <th>ecg_id_10</th>\n",
       "      <th>ecg_id_11</th>\n",
       "      <th>...</th>\n",
       "      <th>ecg_id_21814</th>\n",
       "      <th>ecg_id_21818</th>\n",
       "      <th>ecg_id_21822</th>\n",
       "      <th>ecg_id_21823</th>\n",
       "      <th>ecg_id_21825</th>\n",
       "      <th>ecg_id_21830</th>\n",
       "      <th>ecg_id_21831</th>\n",
       "      <th>ecg_id_21834</th>\n",
       "      <th>ecg_id_21836</th>\n",
       "      <th>ecg_id_21837</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005931</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>-0.060239</td>\n",
       "      <td>-0.003015</td>\n",
       "      <td>-0.010290</td>\n",
       "      <td>-0.026887</td>\n",
       "      <td>-0.016865</td>\n",
       "      <td>-0.035679</td>\n",
       "      <td>0.022911</td>\n",
       "      <td>0.081075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034303</td>\n",
       "      <td>-0.002773</td>\n",
       "      <td>-0.004394</td>\n",
       "      <td>-0.024438</td>\n",
       "      <td>-0.004379</td>\n",
       "      <td>-0.023332</td>\n",
       "      <td>-0.009111</td>\n",
       "      <td>-0.003128</td>\n",
       "      <td>-0.001082</td>\n",
       "      <td>-0.003083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.035915</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>-0.058801</td>\n",
       "      <td>-0.015128</td>\n",
       "      <td>-0.012348</td>\n",
       "      <td>-0.021893</td>\n",
       "      <td>-0.018043</td>\n",
       "      <td>-0.059561</td>\n",
       "      <td>0.013954</td>\n",
       "      <td>0.108318</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037347</td>\n",
       "      <td>-0.007083</td>\n",
       "      <td>-0.005597</td>\n",
       "      <td>-0.031281</td>\n",
       "      <td>-0.001557</td>\n",
       "      <td>-0.034316</td>\n",
       "      <td>-0.009093</td>\n",
       "      <td>-0.005103</td>\n",
       "      <td>-0.008902</td>\n",
       "      <td>-0.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.058001</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>-0.058535</td>\n",
       "      <td>-0.023865</td>\n",
       "      <td>-0.014023</td>\n",
       "      <td>-0.017562</td>\n",
       "      <td>-0.018971</td>\n",
       "      <td>-0.075514</td>\n",
       "      <td>0.004631</td>\n",
       "      <td>0.129365</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039400</td>\n",
       "      <td>-0.010217</td>\n",
       "      <td>-0.006371</td>\n",
       "      <td>-0.035934</td>\n",
       "      <td>-0.007506</td>\n",
       "      <td>-0.040056</td>\n",
       "      <td>-0.009147</td>\n",
       "      <td>-0.005549</td>\n",
       "      <td>-0.013394</td>\n",
       "      <td>-0.004792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.069719</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.060427</td>\n",
       "      <td>-0.028334</td>\n",
       "      <td>-0.015542</td>\n",
       "      <td>-0.014040</td>\n",
       "      <td>-0.019698</td>\n",
       "      <td>-0.081417</td>\n",
       "      <td>-0.004596</td>\n",
       "      <td>0.143173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040116</td>\n",
       "      <td>-0.011780</td>\n",
       "      <td>-0.006672</td>\n",
       "      <td>-0.037752</td>\n",
       "      <td>-0.026059</td>\n",
       "      <td>-0.038896</td>\n",
       "      <td>-0.009288</td>\n",
       "      <td>-0.003756</td>\n",
       "      <td>-0.013416</td>\n",
       "      <td>-0.004943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.073053</td>\n",
       "      <td>-0.001297</td>\n",
       "      <td>-0.065166</td>\n",
       "      <td>-0.029568</td>\n",
       "      <td>-0.017359</td>\n",
       "      <td>-0.011409</td>\n",
       "      <td>-0.020399</td>\n",
       "      <td>-0.080615</td>\n",
       "      <td>-0.011956</td>\n",
       "      <td>0.152658</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039656</td>\n",
       "      <td>-0.012071</td>\n",
       "      <td>-0.006672</td>\n",
       "      <td>-0.037317</td>\n",
       "      <td>-0.052896</td>\n",
       "      <td>-0.033458</td>\n",
       "      <td>-0.009493</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>-0.010129</td>\n",
       "      <td>-0.004506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>-0.004792</td>\n",
       "      <td>-0.000882</td>\n",
       "      <td>-0.012882</td>\n",
       "      <td>0.010247</td>\n",
       "      <td>-0.004111</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>-0.003448</td>\n",
       "      <td>-0.010734</td>\n",
       "      <td>-0.008198</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002073</td>\n",
       "      <td>-0.001340</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>-0.005392</td>\n",
       "      <td>-0.005708</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>-0.013651</td>\n",
       "      <td>0.004181</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>-0.013701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>-0.005808</td>\n",
       "      <td>-0.001008</td>\n",
       "      <td>-0.012081</td>\n",
       "      <td>0.008044</td>\n",
       "      <td>-0.003822</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>-0.003160</td>\n",
       "      <td>-0.011008</td>\n",
       "      <td>-0.007791</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001965</td>\n",
       "      <td>-0.001468</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>-0.005108</td>\n",
       "      <td>-0.005231</td>\n",
       "      <td>-0.001454</td>\n",
       "      <td>-0.012495</td>\n",
       "      <td>0.003884</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>-0.012848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>-0.005111</td>\n",
       "      <td>-0.001145</td>\n",
       "      <td>-0.011265</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>-0.003394</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>-0.002872</td>\n",
       "      <td>-0.009836</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001857</td>\n",
       "      <td>-0.001562</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>-0.004633</td>\n",
       "      <td>-0.004764</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>-0.011313</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>-0.011940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>-0.001930</td>\n",
       "      <td>-0.001271</td>\n",
       "      <td>-0.010408</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>-0.002777</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>-0.002583</td>\n",
       "      <td>-0.006594</td>\n",
       "      <td>-0.006420</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001745</td>\n",
       "      <td>-0.001592</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>-0.003885</td>\n",
       "      <td>-0.004305</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>-0.010111</td>\n",
       "      <td>0.003321</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>-0.010953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>0.003292</td>\n",
       "      <td>-0.001382</td>\n",
       "      <td>-0.009516</td>\n",
       "      <td>0.007993</td>\n",
       "      <td>-0.002010</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>-0.002292</td>\n",
       "      <td>-0.001657</td>\n",
       "      <td>-0.005433</td>\n",
       "      <td>-0.003589</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001626</td>\n",
       "      <td>-0.001568</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>-0.002912</td>\n",
       "      <td>-0.003852</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>-0.008898</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>-0.009907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2300 rows Ã— 8938 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ecg_id_1  ecg_id_2  ecg_id_3  ecg_id_4  ecg_id_5  ecg_id_6  ecg_id_7  \\\n",
       "0    -0.005931  0.000465 -0.060239 -0.003015 -0.010290 -0.026887 -0.016865   \n",
       "1    -0.035915  0.001053 -0.058801 -0.015128 -0.012348 -0.021893 -0.018043   \n",
       "2    -0.058001  0.000931 -0.058535 -0.023865 -0.014023 -0.017562 -0.018971   \n",
       "3    -0.069719 -0.000002 -0.060427 -0.028334 -0.015542 -0.014040 -0.019698   \n",
       "4    -0.073053 -0.001297 -0.065166 -0.029568 -0.017359 -0.011409 -0.020399   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2295 -0.004792 -0.000882 -0.012882  0.010247 -0.004111  0.001247 -0.003448   \n",
       "2296 -0.005808 -0.001008 -0.012081  0.008044 -0.003822  0.001039 -0.003160   \n",
       "2297 -0.005111 -0.001145 -0.011265  0.006858 -0.003394  0.000796 -0.002872   \n",
       "2298 -0.001930 -0.001271 -0.010408  0.006945 -0.002777  0.000526 -0.002583   \n",
       "2299  0.003292 -0.001382 -0.009516  0.007993 -0.002010  0.000244 -0.002292   \n",
       "\n",
       "      ecg_id_9  ecg_id_10  ecg_id_11  ...  ecg_id_21814  ecg_id_21818  \\\n",
       "0    -0.035679   0.022911   0.081075  ...     -0.034303     -0.002773   \n",
       "1    -0.059561   0.013954   0.108318  ...     -0.037347     -0.007083   \n",
       "2    -0.075514   0.004631   0.129365  ...     -0.039400     -0.010217   \n",
       "3    -0.081417  -0.004596   0.143173  ...     -0.040116     -0.011780   \n",
       "4    -0.080615  -0.011956   0.152658  ...     -0.039656     -0.012071   \n",
       "...        ...        ...        ...  ...           ...           ...   \n",
       "2295 -0.010734  -0.008198   0.004406  ...     -0.002073     -0.001340   \n",
       "2296 -0.011008  -0.007791   0.004976  ...     -0.001965     -0.001468   \n",
       "2297 -0.009836  -0.007221   0.004082  ...     -0.001857     -0.001562   \n",
       "2298 -0.006594  -0.006420   0.001100  ...     -0.001745     -0.001592   \n",
       "2299 -0.001657  -0.005433  -0.003589  ...     -0.001626     -0.001568   \n",
       "\n",
       "      ecg_id_21822  ecg_id_21823  ecg_id_21825  ecg_id_21830  ecg_id_21831  \\\n",
       "0        -0.004394     -0.024438     -0.004379     -0.023332     -0.009111   \n",
       "1        -0.005597     -0.031281     -0.001557     -0.034316     -0.009093   \n",
       "2        -0.006371     -0.035934     -0.007506     -0.040056     -0.009147   \n",
       "3        -0.006672     -0.037752     -0.026059     -0.038896     -0.009288   \n",
       "4        -0.006672     -0.037317     -0.052896     -0.033458     -0.009493   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2295      0.002728     -0.005392     -0.005708     -0.000900     -0.013651   \n",
       "2296      0.002446     -0.005108     -0.005231     -0.001454     -0.012495   \n",
       "2297      0.002206     -0.004633     -0.004764     -0.001291     -0.011313   \n",
       "2298      0.002029     -0.003885     -0.004305     -0.000157     -0.010111   \n",
       "2299      0.001907     -0.002912     -0.003852      0.001753     -0.008898   \n",
       "\n",
       "      ecg_id_21834  ecg_id_21836  ecg_id_21837  \n",
       "0        -0.003128     -0.001082     -0.003083  \n",
       "1        -0.005103     -0.008902     -0.004100  \n",
       "2        -0.005549     -0.013394     -0.004792  \n",
       "3        -0.003756     -0.013416     -0.004943  \n",
       "4        -0.000088     -0.010129     -0.004506  \n",
       "...            ...           ...           ...  \n",
       "2295      0.004181      0.002491     -0.013701  \n",
       "2296      0.003884      0.002146     -0.012848  \n",
       "2297      0.003600      0.002079     -0.011940  \n",
       "2298      0.003321      0.002400     -0.010953  \n",
       "2299      0.003042      0.003038     -0.009907  \n",
       "\n",
       "[2300 rows x 8938 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c17730-f526-4c72-80a3-17c3fa0d656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete any column in which any reading is NaN\n",
    "norm_df = norm_df.dropna(axis=1)\n",
    "mi_df = mi_df.dropna(axis=1)\n",
    "non_mi_df = non_mi_df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "285d5892-07e8-4a68-8f1f-a4bdf2e4de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the order of the ecg recordings\n",
    "import random\n",
    "norm_cols = norm_df.columns.to_list()\n",
    "random.shuffle(norm_cols)\n",
    "mi_cols = mi_df.columns.to_list()\n",
    "random.shuffle(mi_cols)\n",
    "non_mi_cols = non_mi_df.columns.to_list()\n",
    "random.shuffle(non_mi_cols)\n",
    "norm_df = norm_df[norm_cols]\n",
    "mi_df = mi_df[mi_cols]\n",
    "non_mi_df = non_mi_df[non_mi_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3d9314d-963b-4b6b-bf79-a8437bd20447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of norm cases: \n",
      "8938\n",
      "Number of MI cases: \n",
      "4145\n",
      "Number of non_MI cases: \n",
      "7815\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of norm cases: \")\n",
    "print(len(norm_df.columns))\n",
    "print(\"Number of MI cases: \")\n",
    "print(len(mi_df.columns))\n",
    "print(\"Number of non_MI cases: \")\n",
    "print(len(non_mi_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4d68c85-1ab6-4e32-bd91-ed062cee8333",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3676, 8, 345, 1)\n",
      "(8184, 8, 345, 1)\n",
      "(7045, 8, 345, 1)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "mi_beats = []\n",
    "for ecg in mi_df.columns:\n",
    "    _mi_beats = []\n",
    "    peaks = apply_pan_tompkins(mi_df[ecg], n_beats=8)\n",
    "    for peak in peaks.keys():\n",
    "        p = peaks[peak].to_numpy()\n",
    "        \n",
    "        # TODO(simona): For some reason, sometimes it does not return beats of the same length, fix this in the code\n",
    "        if np.shape(p)[0] != 345: continue\n",
    "        \n",
    "        ## Min max scale after detecting beat\n",
    "        p = np.reshape(p, [-1, 1])\n",
    "        p = scaler.fit_transform(p)\n",
    "        _mi_beats.append(p)\n",
    "        \n",
    "    _mi_beats = np.array(_mi_beats)\n",
    "    \n",
    "    # TODO(simona): For some reason, the pan tompkins does not always return n_beats, fix this in the code\n",
    "    if np.shape(_mi_beats)[0] == 8:\n",
    "        # Shuffle sequence of beats\n",
    "        df = pd.DataFrame(np.reshape(_mi_beats, [8,345]))\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        _mi_beats = df.to_numpy()\n",
    "        _mi_beats = np.reshape(_mi_beats, [8,345,1])\n",
    "        mi_beats.append(_mi_beats)\n",
    "\n",
    "norm_beats = []\n",
    "for ecg in norm_df.columns:\n",
    "    _norm_beats = []\n",
    "    peaks = apply_pan_tompkins(norm_df[ecg], n_beats=8)\n",
    "    for peak in peaks.keys():\n",
    "        p = peaks[peak].to_numpy()\n",
    "        \n",
    "        # TODO(simona): For some reason, sometimes it does not return beats of the same length, fix this in the code\n",
    "        if np.shape(p)[0] != 345: continue\n",
    "        \n",
    "        ## Min max scale after detecting beat\n",
    "        p = np.reshape(p, [-1, 1])\n",
    "        p = scaler.fit_transform(p)\n",
    "        _norm_beats.append(p)\n",
    "    \n",
    "    _norm_beats = np.array(_norm_beats)\n",
    "    \n",
    "    # TODO(simona): For some reason, the pan tompkins does not always return n_beats, fix this in the code\n",
    "    if np.shape(_norm_beats)[0] == 8:\n",
    "        df = pd.DataFrame(np.reshape(_norm_beats, [8,345]))\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        _norm_beats = df.to_numpy()\n",
    "        _norm_beats = np.reshape(_norm_beats, [8,345,1])\n",
    "        norm_beats.append(_norm_beats)\n",
    "        \n",
    "non_mi_beats = []\n",
    "for ecg in non_mi_df.columns:\n",
    "    _non_mi_beats = []\n",
    "    peaks = apply_pan_tompkins(non_mi_df[ecg], n_beats=8)\n",
    "    for peak in peaks.keys():\n",
    "        p = peaks[peak].to_numpy()\n",
    "        \n",
    "        # TODO(simona): For some reason, sometimes it does not return beats of the same length, fix this in the code\n",
    "        if np.shape(p)[0] != 345: continue\n",
    "        \n",
    "        ## Min max scale after detecting beat\n",
    "        p = np.reshape(p, [-1, 1])\n",
    "        p = scaler.fit_transform(p)\n",
    "        _non_mi_beats.append(p)\n",
    "   \n",
    "    _non_mi_beats = np.array(_non_mi_beats)\n",
    "    \n",
    "    # TODO(simona): For some reason, the pan tompkins does not always return n_beats, fix this in the code\n",
    "    if np.shape(_non_mi_beats)[0] == 8:\n",
    "        df = pd.DataFrame(np.reshape(_non_mi_beats, [8,345]))\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        _non_mi_beats = df.to_numpy()\n",
    "        _non_mi_beats = np.reshape(_non_mi_beats, [8,345,1])\n",
    "        non_mi_beats.append(_non_mi_beats)\n",
    "    \n",
    "print(np.shape(mi_beats))\n",
    "print(np.shape(norm_beats))\n",
    "print(np.shape(non_mi_beats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa22531-7ac2-4600-b948-6e157ef9ede9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5880, 8, 345, 1)\n",
      "(1472, 8, 345, 1)\n",
      "(5880, 8, 345, 1)\n",
      "(5880, 1, 1)\n",
      "(1472, 8, 345, 1)\n",
      "(1472, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# We are going to make three training and testing sets for each of the models.\n",
    "# We will then use these datasets to train each of the individual one-vs-one classifiers\n",
    "# For each of these datasets, we want a balanced of classes, such that a good classifier can be made.\n",
    "# After, we will then make a 4th dataset to train the meta classifier, without updating the weights of the individual ovo models\n",
    "\n",
    "# Dataset for model 1: MI vs non-MI model\n",
    "\n",
    "# Separate into train and test set with balanced class labels\n",
    "model_1_data_train = np.concatenate((mi_beats[0:int(0.8*len(mi_beats))], non_mi_beats[0:int(0.8*len(mi_beats))]))\n",
    "model_1_data_test = np.concatenate((mi_beats[int(0.8*len(mi_beats)):], non_mi_beats[int(0.8*len(mi_beats)):len(mi_beats)]))\n",
    "\n",
    "# Class labels: MI - 1, non-MI - 0\n",
    "mi_label_model_1 = np.ones((3676,1,1))\n",
    "non_mi_label_model_1 = np.zeros((3676,1,1))\n",
    "\n",
    "model_1_labels_train = np.concatenate((mi_label_model_1[0:int(0.8*len(mi_beats))], non_mi_label_model_1[0:int(0.8*len(mi_beats))]))\n",
    "model_1_labels_test = np.concatenate((mi_label_model_1[int(0.8*len(mi_beats)):], non_mi_label_model_1[int(0.8*len(mi_beats)):len(mi_beats)]))\n",
    "\n",
    "# Shuffle across the first index using the same logic for both the label and the data\n",
    "model_1_data_train, model_1_labels_train = shuffle(model_1_data_train, model_1_labels_train, random_state=42)\n",
    "model_1_data_test, model_1_labels_test = shuffle(model_1_data_test, model_1_labels_test, random_state=42)\n",
    "\n",
    "print(np.shape(model_1_data_train))\n",
    "print(np.shape(model_1_labels_train))\n",
    "\n",
    "print(np.shape(model_1_data_test))\n",
    "print(np.shape(model_1_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "faeb953b-38d6-414c-a9c3-462f00a1a12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 8, 345, 1)\n",
      "(7352, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Dataset for model 2: MI vs norm model\n",
    "model_2_data = np.concatenate((mi_beats, norm_beats[0:3676]))\n",
    "\n",
    "# Class labels: MI - 1, norm - 0\n",
    "mi_label_model_2 = np.ones((3676,1,1))\n",
    "norm_label_model_2 = np.zeros((3676,1,1))\n",
    "\n",
    "model_2_labels = np.concatenate((mi_label_model_2, norm_label_model_2))\n",
    "\n",
    "# Shuffle across the first index using the same logic for both the label and the data\n",
    "model_2_data, model_2_labels = shuffle(model_2_data, model_2_labels, random_state=42)\n",
    "\n",
    "print(np.shape(model_2_data))\n",
    "print(np.shape(model_2_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "104eb2d4-0f35-4155-ab93-e13688c515c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14090, 8, 345, 1)\n",
      "(14090, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Dataset for model 3: norm vs non-MI model\n",
    "model_3_data = np.concatenate((norm_beats[0:7045], non_mi_beats))\n",
    "\n",
    "# Class labels: non-MI - 0, norm - 1\n",
    "non_mi_label_model_3 = np.zeros((7045,1,1))\n",
    "norm_label_model_3 = np.ones((7045,1,1))\n",
    "\n",
    "model_3_labels = np.concatenate((non_mi_label_model_3, norm_label_model_3))\n",
    "\n",
    "# Shuffle across the first index using the same logic for both the label and the data\n",
    "model_3_data, model_3_labels = shuffle(model_3_data, model_3_labels, random_state=42)\n",
    "\n",
    "print(np.shape(model_3_data))\n",
    "print(np.shape(model_3_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bb7220-6b61-4b0a-b772-1b90532a7e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for meta learner: whole dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7026a140-846d-4ca7-a0f5-4dae2157491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate training and testing\n",
    "# 80% of HC + 80% of MI is training\n",
    "# 20% of HC + 20% of MI is testing\n",
    "\n",
    "training_set = pd.concat([hc_beats_df[0:int(0.8*len(hc_beats_df))], mi_beats_df[0:int(0.8*len(mi_beats_df))]], ignore_index=True)\n",
    "testing_set = pd.concat([hc_beats_df[int(0.8*len(hc_beats_df)):], mi_beats_df[int(0.8*len(mi_beats_df)):]], ignore_index=True)\n",
    "\n",
    "# Shuffle Data\n",
    "training_set = training_set.sample(frac=1).reset_index(drop=True)\n",
    "testing_set = testing_set.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33356028-4a3d-420a-9038-319c6321ebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# Drop NaN rows\n",
    "training_set = training_set.dropna()\n",
    "testing_set = testing_set.dropna()\n",
    "\n",
    "# TODO(cegenati): Do we need to standardize data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7562dc3-3def-408f-8a15-a28ddab0701a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c1e7374-72e4-4405-870a-b0e290051a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41334, 345)\n",
      "(41334,)\n",
      "(10333, 345)\n",
      "(10333,)\n"
     ]
    }
   ],
   "source": [
    "# Separate data and labels and convert to tensors\n",
    "\n",
    "x_train = training_set.drop('label', axis=1).to_numpy()\n",
    "y_train = training_set['label'].to_numpy()\n",
    "\n",
    "x_test = testing_set.drop('label', axis=1).to_numpy()\n",
    "y_test = testing_set['label'].to_numpy()\n",
    "\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_test))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4138068a-c464-4c42-a712-4955f015e044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 19:00:20.263944: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 345, 1)]          0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 345, 32)           128       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 345, 32)          128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 345, 32)           3104      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 345, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 172, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 172, 32)           0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 172, 32)           3104      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 172, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 172, 32)           3104      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 172, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 86, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 86, 32)            0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 86, 32)            3104      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 86, 32)           128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 86, 32)            3104      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 86, 32)           128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 43, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 43, 32)            0         \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 43, 32)            3104      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 43, 32)           128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 43, 32)            3104      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 43, 32)           128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 21, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 21, 32)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 672)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                21536     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 16)               64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46,337\n",
      "Trainable params: 45,665\n",
      "Non-trainable params: 672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN Model Architecture\n",
    "import tensorflow as tf\n",
    "\n",
    "beat_length = 345\n",
    "num_feats = 1\n",
    "\n",
    "## Layer 0 - input\n",
    "input = tf.keras.Input(shape=(beat_length,num_feats))\n",
    "\n",
    "## Layers 1-6 - convolutional block\n",
    "x = tf.keras.layers.Conv1D(32, 3,  padding='same', activation='relu')(input)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPool1D(pool_size=2)(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layers 7-12 - convolutional block\n",
    "x = tf.keras.layers.Conv1D(32, 3,  padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPool1D(pool_size=2)(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layers 13-19 - convolutional block\n",
    "x = tf.keras.layers.Conv1D(32, 3,  padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPool1D(pool_size=2)(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layers 19-24 - convolutional block\n",
    "x = tf.keras.layers.Conv1D(32, 3,  padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Conv1D(32, 3, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPool1D(pool_size=2)(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layer 25 - flatten\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "## Layer 26 - dense\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "## Layer 27 - batch norm\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "## Layer 28 - dropout\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layer 29 - dense\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "## Layer 30 - batch norm\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "## Layer 31 - dropout\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layer 32 - dense\n",
    "x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "\n",
    "## Layer 33 - batch norm\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "## Layer 34 - dropout\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "## Layer 35 - output\n",
    "output = tf.keras.layers.Dense(1, activation='softmax')(x)\n",
    "\n",
    "cnn_model = tf.keras.Model(input, output, name=\"cnn_model\")\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26f158bb-7ac1-4126-b1ef-44948abaec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2), loss=tf.keras.losses.BinaryCrossentropy(), metrics=tf.keras.metrics.BinaryAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98b7da94-49f9-4dfa-9e57-a9d1ddf676db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331/331 [==============================] - 63s 181ms/step - loss: 0.6141 - binary_accuracy: 0.7144 - val_loss: 0.5998 - val_binary_accuracy: 0.7142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4d1d26c0d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "# tf.config.experimental_run_functions_eagerly(True)\n",
    "\n",
    "cnn_model.fit(x=x_train, y=y_train, validation_data=[x_test, y_test], batch_size=125, epochs=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90522677-f9af-44f3-be3a-adcdd56378c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
